{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Created on Wed Sep 25 16:03:49 2019\n",
    "@author: Master DS By Anas Morahhib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "        \"You are trying to code TF-IDF all by youreself like a big boy.\",\n",
    "        \"So this is a tinny doc.\",\n",
    "        \"And another tinny doc to test few stuff.\",\n",
    "        \"So in total, we are four documents, have fun ;).\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc (d):\n",
    "    d = d.lower()\n",
    "    return re.sub('[^a-z0-9\\-]+', ' ', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf(t,d) = count of t in d / number of words in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(w,d):\n",
    "    d = clean_doc (d)\n",
    "    d1 = d.split()\n",
    "    d1 = tuple(d1)\n",
    "    return d1.count(w) / len(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(w,D):\n",
    "        df = 0\n",
    "        N = len(D)\n",
    "        for i in range (0, N):\n",
    "            c =  D[i].count(w)\n",
    "            df += 1 if c > 0 else 0\n",
    "        return math.log(N/(df+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(w,d,D):\n",
    "    # Caluculer TF\n",
    "    # tf(t,d) = count of t in d / number of words in d\n",
    "    d1 = TextBlob(d)\n",
    "    count_td = d1.word_counts[w]\n",
    "    number_w = len(d1.words)\n",
    "    tf = count_td / number_w \n",
    "    # calculer idf\n",
    "    # idf(t) = log(N/(df + 1))\n",
    "    df = 0\n",
    "    N = len(D)\n",
    "    \n",
    "    # df(t) = occurrence of t in documents\n",
    "    for i in range (0, N):\n",
    "        d = TextBlob(D[i])\n",
    "        c = d.word_counts[w]\n",
    "        df += 1 if c > 0 else 0\n",
    "    idf = math.log(N/(df+1))\n",
    "    \n",
    "    # tf-idf(t, d) = tf(t, d) * log(N/(df + 1))\n",
    "    \n",
    "    return tf*idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF for word \"boy\" =  0.07692307692307693\n",
      "IDF for word \"boy\" =  0.6931471805599453\n",
      "TF-IDF without TextBlob 0.053319013889226566\n",
      "TF-IDF with TextBlob\" =  0.053319013889226566\n"
     ]
    }
   ],
   "source": [
    "val1 = tf(\"boy\", documents[0])\n",
    "print('TF for word \"boy\" = ',val1)\n",
    "val2 = idf(\"boy\", documents)\n",
    "print('IDF for word \"boy\" = ',val2)\n",
    "print('TF-IDF without TextBlob', val1*val2 )\n",
    "val = tf_idf(\"boy\", documents[0], documents)\n",
    "print('TF-IDF with TextBlob\" = ',val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_to_words (D):\n",
    "    words = []\n",
    "    for i in range (0, len(D)):\n",
    "        d = TextBlob(D[i].lower())\n",
    "        words = set(words).union(set(d.words))\n",
    "    return words    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création et affichage du TDM et DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0         1         2         3\n",
      "we         0.000000  0.000000  0.000000  0.077016\n",
      "so         0.000000  0.047947  0.000000  0.031965\n",
      "in         0.000000  0.000000  0.000000  0.077016\n",
      "this       0.000000  0.115525  0.000000  0.000000\n",
      "test       0.000000  0.000000  0.086643  0.000000\n",
      "all        0.053319  0.000000  0.000000  0.000000\n",
      "by         0.053319  0.000000  0.000000  0.000000\n",
      "have       0.000000  0.000000  0.000000  0.077016\n",
      "you        0.053319  0.000000  0.000000  0.000000\n",
      "documents  0.000000  0.000000  0.000000  0.077016\n",
      "boy        0.053319  0.000000  0.000000  0.000000\n",
      "tinny      0.000000  0.047947  0.035960  0.000000\n",
      "a          0.022129  0.047947  0.000000  0.000000\n",
      "is         0.000000  0.115525  0.000000  0.000000\n",
      "another    0.000000  0.000000  0.086643  0.000000\n",
      "tf-idf     0.053319  0.000000  0.000000  0.000000\n",
      "four       0.000000  0.000000  0.000000  0.077016\n",
      "total      0.000000  0.000000  0.000000  0.077016\n",
      "are        0.022129  0.000000  0.000000  0.031965\n",
      "trying     0.053319  0.000000  0.000000  0.000000\n",
      "fun        0.000000  0.000000  0.000000  0.077016\n",
      "to         0.022129  0.000000  0.035960  0.000000\n",
      "doc        0.000000  0.047947  0.035960  0.000000\n",
      "like       0.053319  0.000000  0.000000  0.000000\n",
      "youreself  0.053319  0.000000  0.000000  0.000000\n",
      "few        0.000000  0.000000  0.086643  0.000000\n",
      "stuff      0.000000  0.000000  0.086643  0.000000\n",
      "and        0.000000  0.000000  0.086643  0.000000\n",
      "code       0.053319  0.000000  0.000000  0.000000\n",
      "big        0.053319  0.000000  0.000000  0.000000\n",
      "         we        so        in      this      test       all        by  \\\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.053319  0.053319   \n",
      "1  0.000000  0.047947  0.000000  0.115525  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.086643  0.000000  0.000000   \n",
      "3  0.077016  0.031965  0.077016  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       have       you  documents  ...       fun        to       doc      like  \\\n",
      "0  0.000000  0.053319   0.000000  ...  0.000000  0.022129  0.000000  0.053319   \n",
      "1  0.000000  0.000000   0.000000  ...  0.000000  0.000000  0.047947  0.000000   \n",
      "2  0.000000  0.000000   0.000000  ...  0.000000  0.035960  0.035960  0.000000   \n",
      "3  0.077016  0.000000   0.077016  ...  0.077016  0.000000  0.000000  0.000000   \n",
      "\n",
      "   youreself       few     stuff       and      code       big  \n",
      "0   0.053319  0.000000  0.000000  0.000000  0.053319  0.053319  \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2   0.000000  0.086643  0.086643  0.086643  0.000000  0.000000  \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[4 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count TF-IDF for evry words in evry documents \n",
    "wordSet = docs_to_words(documents)\n",
    "wordsDocsCount = []\n",
    "for i in range(0, len(documents)):\n",
    "    wordsCount = {}\n",
    "    for word in wordSet:\n",
    "         wordsCount[word] = tf_idf(word,documents[i],documents)\n",
    "    wordsDocsCount.append(wordsCount)\n",
    "\n",
    "# Creation et affichage du TDM\n",
    "print(np.transpose(pd.DataFrame(wordsDocsCount)))\n",
    "\n",
    "#Creation et affichage du DTM \n",
    "print(pd.DataFrame(wordsDocsCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.2857937901066633\n",
      "  (0, 4)\t0.2857937901066633\n",
      "  (0, 17)\t0.2857937901066633\n",
      "  (0, 29)\t0.2857937901066633\n",
      "  (0, 6)\t0.2857937901066633\n",
      "  (0, 0)\t0.2857937901066633\n",
      "  (0, 14)\t0.2857937901066633\n",
      "  (0, 21)\t0.2857937901066633\n",
      "  (0, 7)\t0.2857937901066633\n",
      "  (0, 24)\t0.22532310678351805\n",
      "  (0, 26)\t0.2857937901066633\n",
      "  (0, 3)\t0.22532310678351805\n",
      "  (0, 28)\t0.2857937901066633\n",
      "  (1, 8)\t0.401042746469996\n",
      "  (1, 23)\t0.401042746469996\n",
      "  (1, 16)\t0.5086718718935652\n",
      "  (1, 22)\t0.5086718718935652\n",
      "  (1, 18)\t0.401042746469996\n",
      "  (2, 19)\t0.38166888043140357\n",
      "  (2, 10)\t0.38166888043140357\n",
      "  (2, 20)\t0.38166888043140357\n",
      "  (2, 2)\t0.38166888043140357\n",
      "  (2, 1)\t0.38166888043140357\n",
      "  (2, 8)\t0.3009121292288914\n",
      "  (2, 23)\t0.3009121292288914\n",
      "  (2, 24)\t0.3009121292288914\n",
      "  (3, 12)\t0.3482991925120862\n",
      "  (3, 13)\t0.3482991925120862\n",
      "  (3, 9)\t0.3482991925120862\n",
      "  (3, 11)\t0.3482991925120862\n",
      "  (3, 27)\t0.3482991925120862\n",
      "  (3, 25)\t0.3482991925120862\n",
      "  (3, 15)\t0.3482991925120862\n",
      "  (3, 18)\t0.2746030839848684\n",
      "  (3, 3)\t0.2746030839848684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "#Creation et affichage du DTM \n",
    "X = vectorizer.fit_transform(documents)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les deux matrices du question 5 et 6 ne sont pas identique:\n",
    "#### La visualisation:\n",
    "Dans la question 5 on affiche les documents en colonnes et les features en lignes et la valeur tf-idf et l'intersection entre les deux.\n",
    "Par contre dans la question 6 on a deux colonnes, la premier colonne est pour identifier un mot par l'indice de son document et son indice dans la liste des mots et la deusième c'est sa valeur tf-idf.\n",
    "Ce type de matrice s'appelle une matrice creuse, selon wikipedia c'est une matrice contenant beaucoup de zéros, Ces données sont facilement compressibles, et cette compression amène presque à chaque fois une baisse significative de la consommation mémoire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "d1 = nltk.corpus.gutenberg.raw('shakespeare-caesar.txt')\n",
    "d2 = nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')\n",
    "d3 = nltk.corpus.gutenberg.raw('shakespeare-macbeth.txt')\n",
    "\n",
    "docs.append(d1)\n",
    "docs.append(d2)\n",
    "docs.append(d3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation et affichage du DTM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "#Creation et affichage du DTM \n",
    "X = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 51015)\n",
      "  (0, 22043)\t0.001043795799257597\n",
      "  (0, 29582)\t0.001043795799257597\n",
      "  (0, 13747)\t0.0006164826137042619\n",
      "  (0, 30075)\t0.0007938336096451947\n",
      "  (0, 12674)\t0.0007938336096451947\n",
      "  (0, 9635)\t0.0007938336096451947\n",
      "  (0, 16965)\t0.001043795799257597\n",
      "  (0, 43126)\t0.001043795799257597\n",
      "  (0, 15529)\t0.001043795799257597\n",
      "  (0, 41038)\t0.001043795799257597\n",
      "  (0, 3389)\t0.001043795799257597\n",
      "  (0, 23249)\t0.0007938336096451947\n",
      "  (0, 34198)\t0.001043795799257597\n",
      "  (0, 44636)\t0.001043795799257597\n",
      "  (0, 13595)\t0.001043795799257597\n",
      "  (0, 37383)\t0.0007938336096451947\n",
      "  (0, 19615)\t0.001043795799257597\n",
      "  (0, 30614)\t0.001043795799257597\n",
      "  (0, 37979)\t0.001043795799257597\n",
      "  (0, 23596)\t0.001043795799257597\n",
      "  (0, 24401)\t0.001043795799257597\n",
      "  (0, 36203)\t0.001043795799257597\n",
      "  (0, 28202)\t0.001043795799257597\n",
      "  (0, 5192)\t0.0007938336096451947\n",
      "  (0, 18967)\t0.0007938336096451947\n",
      "  :\t:\n",
      "  (2, 28642)\t0.12014092945824126\n",
      "  (2, 22484)\t0.025484439582051176\n",
      "  (2, 47739)\t0.08591896773377253\n",
      "  (2, 42980)\t0.07572519190095206\n",
      "  (2, 21305)\t0.1368878468978749\n",
      "  (2, 15315)\t0.006553141606813159\n",
      "  (2, 50252)\t0.1499941301115012\n",
      "  (2, 19500)\t0.0036406342260073108\n",
      "  (2, 18356)\t0.008009395297216084\n",
      "  (2, 38521)\t0.0021843805356043865\n",
      "  (2, 30740)\t0.0036406342260073108\n",
      "  (2, 7386)\t0.0036406342260073108\n",
      "  (2, 1136)\t0.3975572574799983\n",
      "  (2, 12207)\t0.05897827446131843\n",
      "  (2, 32782)\t0.0036406342260073108\n",
      "  (2, 35306)\t0.0007281268452014622\n",
      "  (2, 32790)\t0.0007281268452014622\n",
      "  (2, 220)\t0.0036406342260073108\n",
      "  (2, 36120)\t0.0007281268452014622\n",
      "  (2, 48894)\t0.0007281268452014622\n",
      "  (2, 6325)\t0.03567821541487164\n",
      "  (2, 6488)\t0.0007281268452014622\n",
      "  (2, 29359)\t0.2461068736780942\n",
      "  (2, 45079)\t0.0014562536904029243\n",
      "  (2, 40649)\t0.4732824493809504\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
